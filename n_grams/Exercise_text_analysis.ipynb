{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise: Text analysis\n",
    "\n",
    "In this exercise, we will look at a python class that performs a analysis on a given text. The code as it is appears to run fine for a few 'normal' cases, however as it is untested it is likely that it will not do so well for all input data. \n",
    "\n",
    "Your task is to design a set of tests that ensure the code functions correctly for all possible input data. It should be able to deal with edge cases and suitably fail (e.g. terminate with an exception) for invalid data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When designing your tests, have in mind the following:\n",
    "* What range of cases should the code be able to deal with? \n",
    "* How should the code deal with edge cases?\n",
    "* What should the code do if it encounters invalid input data?\n",
    "* Even for valid input data, does the code always give the same output or is there some randomness? If so, how can the tests be designed to deal with that?\n",
    "\n",
    "\n",
    "A few examples of 'normal' cases have been given. You may wish to create some more input data for running your tests in order to cover the full range of valid input data (and to test the code fails for invalid input data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import n_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 26611 words in the text.\n",
      "\n",
      "Mean, median and mode word length is 4.03351997294352, 4, 3.\n",
      "\n",
      "10 longest words:\n",
      "affectionately\n",
      "contemptuously\n",
      "multiplication\n",
      "disappointment\n",
      "extraordinary\n",
      "straightening\n",
      "inquisitively\n",
      "uncomfortably\n",
      "uncomfortable\n",
      "conversations\n",
      "\n",
      "Most common words:\n",
      "462 x said\n",
      "385 x alice\n",
      "365 x you\n",
      "246 x her\n",
      "180 x all\n",
      "178 x had\n",
      "178 x with\n",
      "170 x but\n",
      "145 x not\n",
      "144 x very\n",
      "\n",
      "Longest n-grams:\n",
      "6 x will you wont you will you\n",
      "5 x and the moral of that is\n",
      "6 x as well as she could\n",
      "5 x as she said this she\n",
      "19 x said the mock turtle\n",
      "16 x she said to herself\n",
      "11 x a minute or two\n",
      "8 x said the march hare\n",
      "7 x said alice in a\n",
      "6 x in a great hurry\n",
      "6 x in a tone of\n",
      "5 x out of the way\n",
      "5 x the little golden key\n",
      "5 x said the duchess and\n",
      "5 x i beg your pardon\n",
      "5 x said the king and\n",
      "5 x the poor little thing\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files = {\"alice\": \"http://www.gutenberg.org/files/11/11-0.txt\", \n",
    "         \"dracula\": \"http://www.gutenberg.org/ebooks/345.txt.utf-8\",\n",
    "         \"sherlock\": \"http://www.gutenberg.org/ebooks/1661.txt.utf-8\",\n",
    "         \"poe\": \"the_raven.txt\"}\n",
    "\n",
    "txt = n_grams.Text(files[\"alice\"])\n",
    "\n",
    "txt.text_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Tests to make the code fail\n",
    "\n",
    "* `blank.txt` - a blank text file. The code has nothing to stop it dividing by zero when it calculates mean word length.\n",
    "* `repeat.txt` - this repeats the first verse of the Edward Lear poem *The Jumblies* 68 times. The longest n-gram function only looks for n-grams 50 words or shorter, so fails to spot this and instead slices up the poem. There are a couple of ways to deal with this. One would be that if the code finds an n-gram of length 50, check to see if this is a substring of a longer one until no longer find n-grams. Alternatively, could start looking for n-grams of length 2 and increase until no more are found, then eliminate substrings.\n",
    "* `http://www.gutenberg.org/ebooks/844.epub.images?session_id=0fa3233ff1abe287d4a1ce534e052624dc702aec` - this is an EPUB file, so the code will not be able to read it\n",
    "* Longest words and n-grams are both stored in dictionaries, so the in which these are printed will often vary between runs. Care should be taken when designing tests to account for this!\n",
    "* `short.txt` - Length of file is only 5 words, so when code prints out '10 longest words', it only actually prints out 5. This is a minor error, but nonetheless is not correct behaviour.\n",
    "* `nile.csv` - this is just a load of numbers, so results are pretty meaningless. Code should really check it's looking at an actual text file."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  },
  "livereveal": {
   "height": 768,
   "width": 1224
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
